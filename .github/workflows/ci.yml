name: Build, test and Release
on:
  push:
    branches:
      - master
  pull_request:
  release:
    types:
      - published

jobs:
  build:
    strategy:
      matrix:
        python-version: [3.6, 3.7, 3.8]
        include:
          - python-version: 3.7
            tox-py: py37
          - python-version: 3.6
            tox-py: py36
          - python-version: 3.8
            tox-py: py38
    runs-on: ubuntu-18.04
    steps:
    - uses: actions/checkout@v1
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v1
      with:
        python-version: ${{ matrix.python-version }}
    - uses: actions/cache@v1
      with:
        path: ./venv
        key: ${{ runner.os }}-build-virtualenv-${{ matrix.tox-py }}-${{ hashFiles('**/requirements.txt') }}-${{ hashFiles('**/requirements-test.txt') }}
        restore-keys: |
          ${{ runner.os }}-build-virtualenv-${{ matrix.tox-py }}-
    - name: Install dependencies
      run: |
        python -m venv venv
        . venv/bin/activate
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install tox
    - name: Lint with flake8
      run: |
        pip install flake8
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics --ignore=W503
    - name: Run tox
      run: |
        . venv/bin/activate
        tox -e ${{ matrix.tox-py }}
  integration-tests:
    needs: build
    continue-on-error: ${{ matrix.experimental }}
    strategy:
        fail-fast: false
        matrix:
          python-version: [3.6, 3.7]
          it-backend: [local, s3, gcs]
          # IBM not included by default due to lite plan quota being easily exceeded
          # it-backend: [local, s3, gcs, ibm]
          cassandra-version: [2.2.14, 3.11.7, 'github:apache/trunk']
          experimental: [false]
          include:
            - python-version: 3.7
              tox-py: py37
            - python-version: 3.6
              tox-py: py36
    runs-on: ubuntu-18.04
    steps:
    - uses: actions/checkout@v1
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v1
      with:
        python-version: ${{ matrix.python-version }}
    - name: Setup Java Action
      uses: actions/setup-java@v1
      with:
        java-version: '1.8'
        architecture: x64
    - uses: actions/cache@v1
      with:
        path: ./venv
        key: ${{ runner.os }}-integration-tests-virtualenv-${{ matrix.tox-py }}-${{ hashFiles('**/requirements.txt') }}-${{ hashFiles('**/requirements-test.txt') }}
        restore-keys: |
          ${{ runner.os }}-integration-tests-virtualenv-${{ matrix.tox-py }}-
    - name: Install dependencies
      run: |
        python -m venv venv
        . venv/bin/activate
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install ccm
    - name: Run integration tests
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.BUCKET_KEY }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.BUCKET_SECRET }}
      run: |
        set -e
        if [[ ( -n "${AWS_ACCESS_KEY_ID}" && "${{ matrix.it-backend }}" == "s3" ) || ( "${{ matrix.it-backend }}" == "local" ) || ( -n '${{ secrets.MEDUSA_GCS_CREDENTIALS }}' && "${{ matrix.it-backend }}" == "gcs" ) || ( -n '${{ secrets.MEDUSA_IBM_CREDENTIALS }}' && "${{ matrix.it-backend }}" == "ibm" ) ]];
        then
          . venv/bin/activate
          if [[ "${{ matrix.it-backend }}" == "ibm" ]];
          then
            # Prevent awscli from using AWS secrets in case we're running against IBM cloud
            unset AWS_ACCESS_KEY_ID
            unset AWS_SECRET_ACCESS_KEY
          fi
          # Write GCS service account credentials to a file
          echo '${{ secrets.MEDUSA_GCS_CREDENTIALS }}' > ~/medusa_credentials.json
          mkdir ~/.aws
          printf "%s" '${{ secrets.MEDUSA_IBM_CREDENTIALS }}' > ~/.aws/ibm_credentials
          # This fake cluster needs to be created first so that the integration tests pass in GH actions. Don't ask me why...
          ccm create test_cluster -v binary:3.11.4 -n 1 --vnodes
          ccm node1 updateconf 'storage_port: 7011'
          ccm node1 updateconf 'concurrent_reads: 4'
          ccm node1 updateconf 'concurrent_writes: 4'
          ccm node1 updateconf 'concurrent_counter_writes: 4'
          ccm node1 updateconf 'num_tokens: 4'
          sed -i 's/#MAX_HEAP_SIZE="4G"/MAX_HEAP_SIZE="256m"/' ~/.ccm/test_cluster/node1/conf/cassandra-env.sh
          sed -i 's/#HEAP_NEWSIZE="800M"/HEAP_NEWSIZE="200M"/' ~/.ccm/test_cluster/node1/conf/cassandra-env.sh
          ccm start -v
          ccm showlastlog|tail -100
          ccm stop
          if [ "${{ matrix.it-backend }}" == "s3" ]
          then
            ./run_integration_tests.sh -v --s3 --no-local --cassandra-version=${{ matrix.cassandra-version }}
          elif [ "${{ matrix.it-backend }}" == "gcs" ]
          then
            ./run_integration_tests.sh -v --gcs --no-local --cassandra-version=${{ matrix.cassandra-version }}
          elif [ "${{ matrix.it-backend }}" == "ibm" ]
          then
            ./run_integration_tests.sh -v --ibm --no-local --cassandra-version=${{ matrix.cassandra-version }}
          else
            ./run_integration_tests.sh -v --cassandra-version=${{ matrix.cassandra-version }}
          fi
        fi

  release:
    # We can only release if the build above succeeded first
    needs: [build, integration-tests]
    if: github.event_name == 'release' && github.event.action == 'published'
    runs-on: ubuntu-18.04
    steps:
    - uses: actions/checkout@v1
    - name: Build and publish Debian
      env:
        BINTRAY_USERNAME: ${{ secrets.BINTRAY_USERNAME }}
        BINTRAY_KEY: ${{ secrets.BINTRAY_KEY }}
        SUITES: "bionic xenial buster stretch"
      run: |
        cd packaging/docker-build
        $all_suites=($SUITES) # dash supports arrays expansion
        for suite in $all_suites
        do
          docker-compose build "cassandra-medusa-builder-${suite} \
            && docker-compose run "cassandra-medusa-builder-${suite}"
        done
        cd ../..
        version=$(cat VERSION)
        for suite in $all_suites
        do
          if [ -f "packages/cassandra-medusa_${version}-0~${suite}0_amd64.deb" ]; then
            echo "uploading packages/cassandra-medusa_${version}-0~${suite}0_amd64.deb from ${suite} to Bintray"
            curl -T "packages/cassandra-medusa_${version}-0~${suite}0_amd64.deb" \
              -u${BINTRAY_USERNAME}:${BINTRAY_KEY} \
              -H X-Bintray-Debian-Distribution:${suite} -H X-Bintray-Debian-Component:main -H X-Bintray-Debian-Architecture:amd64 -H X-Bintray-Version:${version} \
              https://api.bintray.com/content/thelastpickle/medusa-deb/cassandra-medusa/${version}/cassandra-medusa_${version}-0~${suite}0_amd64.deb
          else
            echo "Error: no packages found for ${suite}"
          fi
        done
        echo "Publishing release in Bintray"
        curl -X POST -u${BINTRAY_USERNAME}:${BINTRAY_KEY} https://api.bintray.com/content/thelastpickle/medusa-deb/cassandra-medusa/${version}/publish
    - name: Set up Python 3.6
      uses: actions/setup-python@v1
      with:
        python-version: 3.6
    - name: Install dependencies
      run: |
        sudo curl -L "https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        sudo chmod +x /usr/local/bin/docker-compose
        sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
        python -m venv venv
        . venv/bin/activate
        python -m pip install --upgrade pip
    - name: Build and publish to pypi
      env:
        TWINE_USERNAME: ${{ secrets.PYPI_USERNAME }}
        TWINE_PASSWORD: ${{ secrets.PYPI_PASSWORD }}
      run: |
        . venv/bin/activate
        pip install setuptools wheel twine
        python setup.py sdist bdist_wheel
        twine upload dist/*
